{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8871bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import feature as detector\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('./img/pic3.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load the face detection cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "# for (x, y, w, h) in faces:\n",
    "#     cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "x, y, w, h = faces[0]\n",
    "cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the input image\n",
    "image = cv2.imread('./img/pic4.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Load the face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=10)\n",
    "\n",
    "# If a face is detected, extract the region of interest (ROI)\n",
    "\n",
    "x, y, w, h = faces[0]\n",
    "roi = image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "# Create a mask of the ROI\n",
    "mask = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "mask[mask > 0] = 0\n",
    "\n",
    "# Apply the mask to the ROI and create a new image\n",
    "result = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "\n",
    "# Replace the ROI with the new image in the original image\n",
    "image[y:y+h, x:x+w] = result\n",
    "\n",
    "# Display the result\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load the face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Extract the face pixels\n",
    "    x, y, w, h = faces[0]\n",
    "    face_pixels = image[y:y+h, x:x+w]\n",
    "#     face_pixels = []\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         face_pixels.extend(image[y:y+h, x:x+w].reshape(-1, 3))\n",
    "\n",
    "    return face_pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    \n",
    "    # Convert to grayscale if necessary\n",
    "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Apply Gaussian blur to remove noise\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to binarize image\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "\n",
    "    \n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Load the face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Extract the face pixels\n",
    "    face_pixels = []\n",
    "    x, y, w, h = faces[0]\n",
    "    face_pixels.append(image[y:y+h, x:x+w])\n",
    "    \n",
    "#     face_pixels = []\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         face_pixels.append(image[y:y+h, x:x+w])\n",
    "\n",
    "    # Combine the face pixels into a single image\n",
    "    if len(face_pixels) > 0:\n",
    "        face_image = np.concatenate(face_pixels, axis=1)\n",
    "    else:\n",
    "        face_image = np.zeros((1,1,3), np.uint8)\n",
    "\n",
    "    return face_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect faces and extract face pixels\n",
    "face_pixels = detect_faces('./img/pic3.png')\n",
    "\n",
    "\n",
    "# # Show the face image\n",
    "# plt.imshow(face_pixels)\n",
    "# plt.show()\n",
    "im = preprocess_image(face_pixels)\n",
    "\n",
    "\n",
    "# Show the face image\n",
    "# Show the image in grayscale\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f05b45",
   "metadata": {},
   "source": [
    "# video face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98404d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# To capture video from webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# To use a video file as input\n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "# Loop through the frames\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow('img', img)\n",
    "\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0482c",
   "metadata": {},
   "source": [
    "# Test data create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3ff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_test_images(image_dir, test_dir, num_test_images):\n",
    "    # Remove the existing test directory if it exists\n",
    "    if os.path.exists(test_dir):\n",
    "        shutil.rmtree(test_dir)\n",
    "\n",
    "    # Create the test directory\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "    # Get a list of all image file names in the directory\n",
    "    image_files = os.listdir(image_dir)\n",
    "\n",
    "    # Shuffle the list of image file names randomly\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Select the specified number of images as test images\n",
    "    test_files = image_files[:num_test_images]\n",
    "\n",
    "    # Iterate over the test image files and copy them to the test directory\n",
    "    for image_file in test_files:\n",
    "        # Get the full path of the image file\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        # Get the label (image name) without the file extension\n",
    "        label = os.path.splitext(image_file)[0]\n",
    "\n",
    "        # Define the new file name for the test image\n",
    "        new_filename = label + '.jpg'\n",
    "\n",
    "        # Define the full path of the test image file\n",
    "        new_filepath = os.path.join(test_dir, new_filename)\n",
    "\n",
    "        # Copy the test image file to the test directory\n",
    "        shutil.copy(image_path, new_filepath)\n",
    "\n",
    "# Usage example\n",
    "image_dir = './img/'\n",
    "test_dir = './test_images/'\n",
    "num_test_images = 10\n",
    "\n",
    "create_test_images(image_dir, test_dir, num_test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdff97",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e68ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_dataset(directory):\n",
    "    # Load the face cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "    # List of image file extensions to read\n",
    "    image_exts = ['jpg', 'jpeg', 'png', 'bmp']\n",
    "    i=0\n",
    "    # Detect faces in all images in the directory\n",
    "    faces_list = []\n",
    "    label = []\n",
    "    for ext in image_exts:\n",
    "        for filename in glob.glob(os.path.join(directory, f'*.{ext}')):\n",
    "            temp = os.path.splitext(os.path.basename(filename))[0]\n",
    "            i = i+1\n",
    "    #         print(i,'read image :',temp)\n",
    "            img = cv2.imread(filename)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "            x, y, w, h = faces[0]\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            faces_list.append(face)\n",
    "            label.append(temp)\n",
    "            \n",
    "    return faces_list,label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cae27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './img'\n",
    "\n",
    "faces_list,label = load_image_dataset(directory)\n",
    "\n",
    "# Display the faces\n",
    "if len(faces_list) > 0:\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    num_faces = len(faces_list)\n",
    "    rows = cols = int(num_faces**0.5) + 1 if int(num_faces**0.5)**2 < num_faces else int(num_faces**0.5)\n",
    "    for i, face in enumerate(faces_list):\n",
    "        fig.add_subplot(rows, cols, i+1)\n",
    "        plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No faces detected in any images.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb8954",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb743ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(image):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Gaussian blur\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    # Apply histogram equalization\n",
    "    eq = cv2.equalizeHist(blur)\n",
    "\n",
    "    return eq\n",
    "\n",
    "def preprocess_images(images, target_size):\n",
    "    preprocessed_images = []\n",
    "    for image in images:\n",
    "        resized_image = cv2.resize(image, target_size)\n",
    "        preprocessed_image = preprocess(resized_image)\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "    return preprocessed_images\n",
    "\n",
    "def display_images(images, preprocessed_images):\n",
    "    # Display the faces\n",
    "    if len(preprocessed_images) > 0:\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        num_faces = len(preprocessed_images)\n",
    "        rows = cols = int(num_faces**0.5) + 1 if int(num_faces**0.5)**2 < num_faces else int(num_faces**0.5)\n",
    "        for i, face in enumerate(preprocessed_images):\n",
    "            fig.add_subplot(rows, cols, i+1)\n",
    "            plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No faces detected in any images.')\n",
    "\n",
    "# Example usage\n",
    "target_size = (224, 224) \n",
    "preprocessed_face_images = preprocess_images(faces_list,target_size)\n",
    "display_images(faces_list, preprocessed_face_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03194ae2",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33636522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(preprocessed_face_images):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog_features = []\n",
    "\n",
    "    for im in preprocessed_face_images:\n",
    "        if im.shape[0] < 8 or im.shape[1] < 8:\n",
    "            continue  # Skip images that are smaller than the cell size\n",
    "\n",
    "        try:\n",
    "            features = detector.hog(im, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(8, 8))\n",
    "            hog_features.append(features)\n",
    "        except ValueError:\n",
    "            continue  # Skip images that cause a ValueError\n",
    "\n",
    "    hog_features = np.array(hog_features)\n",
    "    print(len(hog_features))\n",
    "    \n",
    "    return hog_features \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features = extract_image_features(preprocessed_face_images)\n",
    "\n",
    "hog_normalize = Normalizer(norm='l2')\n",
    "hog_nor = hog_normalize.transform(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bf551",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f29ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  data into training and testing sets\n",
    "X_train = hog_features\n",
    "y_train = label \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd854318",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './test_images/'\n",
    "X_test,y_test = load_image_dataset(test_dir)\n",
    "X_test = preprocess_images(X_test,target_size)\n",
    "X_test = extract_image_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of Train dataset\",len(X_train))\n",
    "print(\"Length of Test dataset\",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test = np.array([re.findall(r'\\d+', item)[0] for item in y_test])\n",
    "\n",
    "y_train = np.array([re.findall(r'\\d+', item)[0] for item in y_train])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da67a8f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de514d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM classifier on the training data\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edce81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a figure and axes\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = plt.subplot()\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', ax=ax)\n",
    "\n",
    "# Set labels, title, and ticks\n",
    "ax.set_xlabel('Predicted Labels')\n",
    "ax.set_ylabel('True Labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels(y_test)\n",
    "ax.yaxis.set_ticklabels(y_pred)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63033f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
